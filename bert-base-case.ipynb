{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6b9a55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import Model\n",
    "from readers import read_ozrock, convert_to_dataset, get_label_list\n",
    "import torch\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import BertTokenizerFast, BertForTokenClassification, TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7eb86e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "Switching to GPU...\n",
      "Current device index: 0\n",
      "Device name: NVIDIA GeForce RTX 4070 Ti\n"
     ]
    }
   ],
   "source": [
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Switching to GPU...\")\n",
    "    device = torch.device('cuda')\n",
    "print(\"Current device index:\", torch.cuda.current_device())\n",
    "print(\"Device name:\", torch.cuda.get_device_name(torch.cuda.current_device()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f58e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets, label_list, label2id, id2label = read_ozrock('./OzRock/AutoLabelledSet.txt', './OzRock/EvaluationSet.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "633fc8bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load tokenizer and model\n",
    "model_name = 'bert-base-cased'\n",
    "tokenizer = BertTokenizerFast.from_pretrained(model_name)\n",
    "model = BertForTokenClassification.from_pretrained(model_name, num_labels=len(label_list), label2id=label2id, id2label=id2label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38038161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing datasets...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf60af0a53d84587848426f78ff0023a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/31942 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "842875502ef94b959b0a4727418acced",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    logging_dir=\"./logs\",\n",
    "    eval_strategy=\"steps\",\n",
    "    save_strategy=\"steps\",\n",
    "    logging_steps=100,\n",
    "    num_train_epochs=1,\n",
    "    save_total_limit=1,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=16,\n",
    "    learning_rate=5e-5,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\"\n",
    ")\n",
    "\n",
    "model = Model(\n",
    "    device=device,\n",
    "    model_name=model_name,\n",
    "    tokenizer=tokenizer,\n",
    "    model=model,\n",
    "    label_list=label_list\n",
    ")\n",
    "\n",
    "model.set_training_args(training_args)\n",
    "tokenized_datasets = model.tokenize_datasets(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc67e586",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Harry\\OneDrive - The University of Western Australia\\2025\\Honours\\test\\model.py:80: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3993' max='3993' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3993/3993 09:15, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.359400</td>\n",
       "      <td>0.271668</td>\n",
       "      <td>0.498814</td>\n",
       "      <td>0.500275</td>\n",
       "      <td>0.499543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.139700</td>\n",
       "      <td>0.250922</td>\n",
       "      <td>0.582309</td>\n",
       "      <td>0.659162</td>\n",
       "      <td>0.618357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.099700</td>\n",
       "      <td>0.241361</td>\n",
       "      <td>0.608593</td>\n",
       "      <td>0.661175</td>\n",
       "      <td>0.633795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.098900</td>\n",
       "      <td>0.250083</td>\n",
       "      <td>0.621526</td>\n",
       "      <td>0.642687</td>\n",
       "      <td>0.631929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.078300</td>\n",
       "      <td>0.250149</td>\n",
       "      <td>0.706315</td>\n",
       "      <td>0.667399</td>\n",
       "      <td>0.686306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.065900</td>\n",
       "      <td>0.242065</td>\n",
       "      <td>0.689016</td>\n",
       "      <td>0.707304</td>\n",
       "      <td>0.698040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.059900</td>\n",
       "      <td>0.270365</td>\n",
       "      <td>0.710486</td>\n",
       "      <td>0.674721</td>\n",
       "      <td>0.692142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.047100</td>\n",
       "      <td>0.254905</td>\n",
       "      <td>0.718338</td>\n",
       "      <td>0.718470</td>\n",
       "      <td>0.718404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.050500</td>\n",
       "      <td>0.250008</td>\n",
       "      <td>0.703407</td>\n",
       "      <td>0.706755</td>\n",
       "      <td>0.705077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.043400</td>\n",
       "      <td>0.248018</td>\n",
       "      <td>0.702592</td>\n",
       "      <td>0.724327</td>\n",
       "      <td>0.713294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.042000</td>\n",
       "      <td>0.285640</td>\n",
       "      <td>0.714799</td>\n",
       "      <td>0.692294</td>\n",
       "      <td>0.703366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.040900</td>\n",
       "      <td>0.255900</td>\n",
       "      <td>0.708948</td>\n",
       "      <td>0.712063</td>\n",
       "      <td>0.710502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.040200</td>\n",
       "      <td>0.279249</td>\n",
       "      <td>0.725191</td>\n",
       "      <td>0.678199</td>\n",
       "      <td>0.700908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.034300</td>\n",
       "      <td>0.273317</td>\n",
       "      <td>0.723642</td>\n",
       "      <td>0.699799</td>\n",
       "      <td>0.711521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.031600</td>\n",
       "      <td>0.283717</td>\n",
       "      <td>0.726218</td>\n",
       "      <td>0.698700</td>\n",
       "      <td>0.712193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.043200</td>\n",
       "      <td>0.275591</td>\n",
       "      <td>0.714579</td>\n",
       "      <td>0.700714</td>\n",
       "      <td>0.707579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.033100</td>\n",
       "      <td>0.278430</td>\n",
       "      <td>0.731398</td>\n",
       "      <td>0.696321</td>\n",
       "      <td>0.713428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.029900</td>\n",
       "      <td>0.300345</td>\n",
       "      <td>0.744659</td>\n",
       "      <td>0.676368</td>\n",
       "      <td>0.708873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.027300</td>\n",
       "      <td>0.292865</td>\n",
       "      <td>0.721598</td>\n",
       "      <td>0.717371</td>\n",
       "      <td>0.719479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.024200</td>\n",
       "      <td>0.269407</td>\n",
       "      <td>0.720064</td>\n",
       "      <td>0.742998</td>\n",
       "      <td>0.731351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.024900</td>\n",
       "      <td>0.289659</td>\n",
       "      <td>0.737945</td>\n",
       "      <td>0.708768</td>\n",
       "      <td>0.723063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.027900</td>\n",
       "      <td>0.268194</td>\n",
       "      <td>0.739834</td>\n",
       "      <td>0.736042</td>\n",
       "      <td>0.737934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.023900</td>\n",
       "      <td>0.268798</td>\n",
       "      <td>0.733433</td>\n",
       "      <td>0.721215</td>\n",
       "      <td>0.727273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.023900</td>\n",
       "      <td>0.277151</td>\n",
       "      <td>0.727306</td>\n",
       "      <td>0.718653</td>\n",
       "      <td>0.722954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.023900</td>\n",
       "      <td>0.275579</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.720483</td>\n",
       "      <td>0.723862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.025400</td>\n",
       "      <td>0.289042</td>\n",
       "      <td>0.735809</td>\n",
       "      <td>0.699982</td>\n",
       "      <td>0.717448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.019800</td>\n",
       "      <td>0.285578</td>\n",
       "      <td>0.735513</td>\n",
       "      <td>0.724876</td>\n",
       "      <td>0.730156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.016800</td>\n",
       "      <td>0.282449</td>\n",
       "      <td>0.740279</td>\n",
       "      <td>0.738788</td>\n",
       "      <td>0.739533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.017100</td>\n",
       "      <td>0.300357</td>\n",
       "      <td>0.741321</td>\n",
       "      <td>0.719202</td>\n",
       "      <td>0.730094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.315383</td>\n",
       "      <td>0.736852</td>\n",
       "      <td>0.705290</td>\n",
       "      <td>0.720726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3100</td>\n",
       "      <td>0.019400</td>\n",
       "      <td>0.296871</td>\n",
       "      <td>0.744693</td>\n",
       "      <td>0.706388</td>\n",
       "      <td>0.725035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.018400</td>\n",
       "      <td>0.293815</td>\n",
       "      <td>0.730790</td>\n",
       "      <td>0.725975</td>\n",
       "      <td>0.728375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3300</td>\n",
       "      <td>0.019100</td>\n",
       "      <td>0.292834</td>\n",
       "      <td>0.742392</td>\n",
       "      <td>0.710049</td>\n",
       "      <td>0.725861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.018000</td>\n",
       "      <td>0.293956</td>\n",
       "      <td>0.736773</td>\n",
       "      <td>0.718836</td>\n",
       "      <td>0.727694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.017600</td>\n",
       "      <td>0.303505</td>\n",
       "      <td>0.735035</td>\n",
       "      <td>0.717005</td>\n",
       "      <td>0.725908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.014100</td>\n",
       "      <td>0.308124</td>\n",
       "      <td>0.737732</td>\n",
       "      <td>0.726524</td>\n",
       "      <td>0.732085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3700</td>\n",
       "      <td>0.011800</td>\n",
       "      <td>0.311205</td>\n",
       "      <td>0.735436</td>\n",
       "      <td>0.725609</td>\n",
       "      <td>0.730489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>0.016800</td>\n",
       "      <td>0.311027</td>\n",
       "      <td>0.739682</td>\n",
       "      <td>0.715175</td>\n",
       "      <td>0.727222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3900</td>\n",
       "      <td>0.017900</td>\n",
       "      <td>0.308294</td>\n",
       "      <td>0.742364</td>\n",
       "      <td>0.716273</td>\n",
       "      <td>0.729085</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "('bert-base-cased-model\\\\tokenizer_config.json',\n",
       " 'bert-base-cased-model\\\\special_tokens_map.json',\n",
       " 'bert-base-cased-model\\\\vocab.txt',\n",
       " 'bert-base-cased-model\\\\added_tokens.json',\n",
       " 'bert-base-cased-model\\\\tokenizer.json')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(tokenized_datasets)\n",
    "model.trainer.save_model(model_name+\"-model\")\n",
    "model.tokenizer.save_pretrained(model_name+\"-model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036fb79c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.2694065272808075,\n",
       " 'eval_precision': 0.7200638637573177,\n",
       " 'eval_recall': 0.742998352553542,\n",
       " 'eval_f1': 0.7313513513513512,\n",
       " 'eval_runtime': 4.3894,\n",
       " 'eval_samples_per_second': 455.646,\n",
       " 'eval_steps_per_second': 28.478,\n",
       " 'epoch': 1.0}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(tokenized_datasets[\"eval\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62061ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
