{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a0b07e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\GeoTKG\\GeoTKG\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from Reader import TimeMLReader\n",
    "from datasets import DatasetDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22e4bfd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file 1/400\n",
      "Processing file 2/400\n",
      "Processing file 3/400\n",
      "Processing file 4/400\n",
      "Processing file 5/400\n",
      "Processing file 6/400\n",
      "Processing file 7/400\n",
      "Processing file 8/400\n",
      "Processing file 9/400\n",
      "Processing file 10/400\n",
      "Processing file 11/400\n",
      "Processing file 12/400\n",
      "Processing file 13/400\n",
      "Processing file 14/400\n",
      "Processing file 15/400\n",
      "Processing file 16/400\n",
      "Processing file 17/400\n",
      "Processing file 18/400\n",
      "Processing file 19/400\n",
      "Processing file 20/400\n",
      "Processing file 21/400\n",
      "Processing file 22/400\n",
      "Processing file 23/400\n",
      "Processing file 24/400\n",
      "Processing file 25/400\n",
      "Processing file 26/400\n",
      "Processing file 27/400\n",
      "Processing file 28/400\n",
      "Processing file 29/400\n",
      "Processing file 30/400\n",
      "Processing file 31/400\n",
      "Processing file 32/400\n",
      "Processing file 33/400\n",
      "Processing file 34/400\n",
      "Processing file 35/400\n",
      "Processing file 36/400\n",
      "Processing file 37/400\n",
      "Processing file 38/400\n",
      "Processing file 39/400\n",
      "Processing file 40/400\n",
      "Processing file 41/400\n",
      "Processing file 42/400\n",
      "Processing file 43/400\n",
      "Processing file 44/400\n",
      "Processing file 45/400\n",
      "Processing file 46/400\n",
      "Processing file 47/400\n",
      "Processing file 48/400\n",
      "Processing file 49/400\n",
      "Processing file 50/400\n",
      "Processing file 51/400\n",
      "Processing file 52/400\n",
      "Processing file 53/400\n",
      "Processing file 54/400\n",
      "Processing file 55/400\n",
      "Processing file 56/400\n",
      "Processing file 57/400\n",
      "Processing file 58/400\n",
      "Processing file 59/400\n",
      "Processing file 60/400\n",
      "Processing file 61/400\n",
      "Processing file 62/400\n",
      "Processing file 63/400\n",
      "Processing file 64/400\n",
      "Processing file 65/400\n",
      "Processing file 66/400\n",
      "Processing file 67/400\n",
      "Processing file 68/400\n",
      "Processing file 69/400\n",
      "Processing file 70/400\n",
      "Processing file 71/400\n",
      "Processing file 72/400\n",
      "Processing file 73/400\n",
      "Processing file 74/400\n",
      "Processing file 75/400\n",
      "Processing file 76/400\n",
      "Processing file 77/400\n",
      "Processing file 78/400\n",
      "Processing file 79/400\n",
      "Processing file 80/400\n",
      "Processing file 81/400\n",
      "Processing file 82/400\n",
      "Processing file 83/400\n",
      "Processing file 84/400\n",
      "Processing file 85/400\n",
      "Processing file 86/400\n",
      "Processing file 87/400\n",
      "Processing file 88/400\n",
      "Processing file 89/400\n",
      "Processing file 90/400\n",
      "Processing file 91/400\n",
      "Processing file 92/400\n",
      "Processing file 93/400\n",
      "Processing file 94/400\n",
      "Processing file 95/400\n",
      "Processing file 96/400\n",
      "Processing file 97/400\n",
      "Processing file 98/400\n",
      "Processing file 99/400\n",
      "Processing file 100/400\n",
      "Processing file 101/400\n",
      "Processing file 102/400\n",
      "Processing file 103/400\n",
      "Processing file 104/400\n",
      "Processing file 105/400\n",
      "Processing file 106/400\n",
      "Processing file 107/400\n",
      "Processing file 108/400\n",
      "Processing file 109/400\n",
      "Processing file 110/400\n",
      "Processing file 111/400\n",
      "Processing file 112/400\n",
      "Processing file 113/400\n",
      "Processing file 114/400\n",
      "Processing file 115/400\n",
      "Processing file 116/400\n",
      "Processing file 117/400\n",
      "Processing file 118/400\n",
      "Processing file 119/400\n",
      "Processing file 120/400\n",
      "Processing file 121/400\n",
      "Processing file 122/400\n",
      "Processing file 123/400\n",
      "Processing file 124/400\n",
      "Processing file 125/400\n",
      "Processing file 126/400\n",
      "Processing file 127/400\n",
      "Processing file 128/400\n",
      "Processing file 129/400\n",
      "Processing file 130/400\n",
      "Processing file 131/400\n",
      "Processing file 132/400\n",
      "Processing file 133/400\n",
      "Processing file 134/400\n",
      "Processing file 135/400\n",
      "Processing file 136/400\n",
      "Processing file 137/400\n",
      "Processing file 138/400\n",
      "Processing file 139/400\n",
      "Processing file 140/400\n",
      "Processing file 141/400\n",
      "Processing file 142/400\n",
      "Processing file 143/400\n",
      "Processing file 144/400\n",
      "Processing file 145/400\n",
      "Processing file 146/400\n",
      "Processing file 147/400\n",
      "Processing file 148/400\n",
      "Processing file 149/400\n",
      "Processing file 150/400\n",
      "Processing file 151/400\n",
      "Processing file 152/400\n",
      "Processing file 153/400\n",
      "Processing file 154/400\n",
      "Processing file 155/400\n",
      "Processing file 156/400\n",
      "Processing file 157/400\n",
      "Processing file 158/400\n",
      "Processing file 159/400\n",
      "Processing file 160/400\n",
      "Processing file 161/400\n",
      "Processing file 162/400\n",
      "Processing file 163/400\n",
      "Processing file 164/400\n",
      "Processing file 165/400\n",
      "Processing file 166/400\n",
      "Processing file 167/400\n",
      "Processing file 168/400\n",
      "Processing file 169/400\n",
      "Processing file 170/400\n",
      "Processing file 171/400\n",
      "Processing file 172/400\n",
      "Processing file 173/400\n",
      "Processing file 174/400\n",
      "Processing file 175/400\n",
      "Processing file 176/400\n",
      "Processing file 177/400\n",
      "Processing file 178/400\n",
      "Processing file 179/400\n",
      "Processing file 180/400\n",
      "Processing file 181/400\n",
      "Processing file 182/400\n",
      "Processing file 183/400\n",
      "Processing file 184/400\n",
      "Processing file 185/400\n",
      "Processing file 186/400\n",
      "Processing file 187/400\n",
      "Processing file 188/400\n",
      "Processing file 189/400\n",
      "Processing file 190/400\n",
      "Processing file 191/400\n",
      "Processing file 192/400\n",
      "Processing file 193/400\n",
      "Processing file 194/400\n",
      "Processing file 195/400\n",
      "Processing file 196/400\n",
      "Processing file 197/400\n",
      "Processing file 198/400\n",
      "Processing file 199/400\n",
      "Processing file 200/400\n",
      "Processing file 201/400\n",
      "Processing file 202/400\n",
      "Processing file 203/400\n",
      "Processing file 204/400\n",
      "Processing file 205/400\n",
      "Processing file 206/400\n",
      "Processing file 207/400\n",
      "Processing file 208/400\n",
      "Processing file 209/400\n",
      "Processing file 210/400\n",
      "Processing file 211/400\n",
      "Processing file 212/400\n",
      "Processing file 213/400\n",
      "Processing file 214/400\n",
      "Processing file 215/400\n",
      "Processing file 216/400\n",
      "Processing file 217/400\n",
      "Processing file 218/400\n",
      "Processing file 219/400\n",
      "Processing file 220/400\n",
      "Processing file 221/400\n",
      "Processing file 222/400\n",
      "Processing file 223/400\n",
      "Processing file 224/400\n",
      "Processing file 225/400\n",
      "Processing file 226/400\n",
      "Processing file 227/400\n",
      "Processing file 228/400\n",
      "Processing file 229/400\n",
      "Processing file 230/400\n",
      "Processing file 231/400\n",
      "Processing file 232/400\n",
      "Processing file 233/400\n",
      "Processing file 234/400\n",
      "Processing file 235/400\n",
      "Processing file 236/400\n",
      "Processing file 237/400\n",
      "Processing file 238/400\n",
      "Processing file 239/400\n",
      "Processing file 240/400\n",
      "Processing file 241/400\n",
      "Processing file 242/400\n",
      "Processing file 243/400\n",
      "Processing file 244/400\n",
      "Processing file 245/400\n",
      "Processing file 246/400\n",
      "Processing file 247/400\n",
      "Processing file 248/400\n",
      "Processing file 249/400\n",
      "Processing file 250/400\n",
      "Processing file 251/400\n",
      "Processing file 252/400\n",
      "Processing file 253/400\n",
      "Processing file 254/400\n",
      "Processing file 255/400\n",
      "Processing file 256/400\n",
      "Processing file 257/400\n",
      "Processing file 258/400\n",
      "Processing file 259/400\n",
      "Processing file 260/400\n",
      "Processing file 261/400\n",
      "Processing file 262/400\n",
      "Processing file 263/400\n",
      "Processing file 264/400\n",
      "Processing file 265/400\n",
      "Processing file 266/400\n",
      "Processing file 267/400\n",
      "Processing file 268/400\n",
      "Processing file 269/400\n",
      "Processing file 270/400\n",
      "Processing file 271/400\n",
      "Processing file 272/400\n",
      "Processing file 273/400\n",
      "Processing file 274/400\n",
      "Processing file 275/400\n",
      "Processing file 276/400\n",
      "Processing file 277/400\n",
      "Processing file 278/400\n",
      "Processing file 279/400\n",
      "Processing file 280/400\n",
      "Processing file 281/400\n",
      "Processing file 282/400\n",
      "Processing file 283/400\n",
      "Processing file 284/400\n",
      "Processing file 285/400\n",
      "Processing file 286/400\n",
      "Processing file 287/400\n",
      "Processing file 288/400\n",
      "Processing file 289/400\n",
      "Processing file 290/400\n",
      "Processing file 291/400\n",
      "Processing file 292/400\n",
      "Processing file 293/400\n",
      "Processing file 294/400\n",
      "Processing file 295/400\n",
      "Processing file 296/400\n",
      "Processing file 297/400\n",
      "Processing file 298/400\n",
      "Processing file 299/400\n",
      "Processing file 300/400\n",
      "Processing file 301/400\n",
      "Processing file 302/400\n",
      "Processing file 303/400\n",
      "Processing file 304/400\n",
      "Processing file 305/400\n",
      "Processing file 306/400\n",
      "Processing file 307/400\n",
      "Processing file 308/400\n",
      "Processing file 309/400\n",
      "Processing file 310/400\n",
      "Processing file 311/400\n",
      "Processing file 312/400\n",
      "Processing file 313/400\n",
      "Processing file 314/400\n",
      "Processing file 315/400\n",
      "Processing file 316/400\n",
      "Processing file 317/400\n",
      "Processing file 318/400\n",
      "Processing file 319/400\n",
      "Processing file 320/400\n",
      "Processing file 321/400\n",
      "Processing file 322/400\n",
      "Processing file 323/400\n",
      "Processing file 324/400\n",
      "Processing file 325/400\n",
      "Processing file 326/400\n",
      "Processing file 327/400\n",
      "Processing file 328/400\n",
      "Processing file 329/400\n",
      "Processing file 330/400\n",
      "Processing file 331/400\n",
      "Processing file 332/400\n",
      "Processing file 333/400\n",
      "Processing file 334/400\n",
      "Processing file 335/400\n",
      "Processing file 336/400\n",
      "Processing file 337/400\n",
      "Processing file 338/400\n",
      "Processing file 339/400\n",
      "Processing file 340/400\n",
      "Processing file 341/400\n",
      "Processing file 342/400\n",
      "Processing file 343/400\n",
      "Processing file 344/400\n",
      "Processing file 345/400\n",
      "Processing file 346/400\n",
      "Processing file 347/400\n",
      "Processing file 348/400\n",
      "Processing file 349/400\n",
      "Processing file 350/400\n",
      "Processing file 351/400\n",
      "Processing file 352/400\n",
      "Processing file 353/400\n",
      "Processing file 354/400\n",
      "Processing file 355/400\n",
      "Processing file 356/400\n",
      "Processing file 357/400\n",
      "Processing file 358/400\n",
      "Processing file 359/400\n",
      "Processing file 360/400\n",
      "Processing file 361/400\n",
      "Processing file 362/400\n",
      "Processing file 363/400\n",
      "Processing file 364/400\n",
      "Processing file 365/400\n",
      "Processing file 366/400\n",
      "Processing file 367/400\n",
      "Processing file 368/400\n",
      "Processing file 369/400\n",
      "Processing file 370/400\n",
      "Processing file 371/400\n",
      "Processing file 372/400\n",
      "Processing file 373/400\n",
      "Processing file 374/400\n",
      "Processing file 375/400\n",
      "Processing file 376/400\n",
      "Processing file 377/400\n",
      "Processing file 378/400\n",
      "Processing file 379/400\n",
      "Processing file 380/400\n",
      "Processing file 381/400\n",
      "Processing file 382/400\n",
      "Processing file 383/400\n",
      "Processing file 384/400\n",
      "Processing file 385/400\n",
      "Processing file 386/400\n",
      "Processing file 387/400\n",
      "Processing file 388/400\n",
      "Processing file 389/400\n",
      "Processing file 390/400\n",
      "Processing file 391/400\n",
      "Processing file 392/400\n",
      "Processing file 393/400\n",
      "Processing file 394/400\n",
      "Processing file 395/400\n",
      "Processing file 396/400\n",
      "Processing file 397/400\n",
      "Processing file 398/400\n",
      "Processing file 399/400\n",
      "Processing file 400/400\n"
     ]
    }
   ],
   "source": [
    "S0 = TimeMLReader('./rawdata/Tempeval3/Training/TE3-Silver-data-0')\n",
    "#intended_path = './cleandata/Tempeval3/silver-1.json'\n",
    "train_dataset, label_list, label2id, id2label = S0.read(method=\"timex3_bio_tagger\", return_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7484daf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file 1/20\n",
      "Processing file 2/20\n",
      "Processing file 3/20\n",
      "Processing file 4/20\n",
      "Processing file 5/20\n",
      "Processing file 6/20\n",
      "Processing file 7/20\n",
      "Processing file 8/20\n",
      "Processing file 9/20\n",
      "Processing file 10/20\n",
      "Processing file 11/20\n",
      "Processing file 12/20\n",
      "Processing file 13/20\n",
      "Processing file 14/20\n",
      "Processing file 15/20\n",
      "Processing file 16/20\n",
      "Processing file 17/20\n",
      "Processing file 18/20\n",
      "Processing file 19/20\n",
      "Processing file 20/20\n"
     ]
    }
   ],
   "source": [
    "PL = TimeMLReader('./rawdata/Tempeval3/Evaluation/te3-platinum')\n",
    "#intended_path = './cleandata/Tempeval3/platinum.json'\n",
    "eval_dataset, label_list, label2id, id2label = PL.read(method=\"timex3_bio_tagger\", return_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f1e0d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = DatasetDict({\n",
    "        \"train\": train_dataset,\n",
    "        \"eval\": eval_dataset\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52c3349c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "Switching to GPU...\n",
      "Current device index: 0\n",
      "Device name: NVIDIA GeForce RTX 4070 Ti\n"
     ]
    }
   ],
   "source": [
    "from Model import Model\n",
    "import torch\n",
    "from transformers import RobertaForTokenClassification, RobertaTokenizerFast, TrainingArguments\n",
    "\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Switching to GPU...\")\n",
    "    device = torch.device('cuda')\n",
    "print(\"Current device index:\", torch.cuda.current_device())\n",
    "print(\"Device name:\", torch.cuda.get_device_name(torch.cuda.current_device()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7de95e43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForTokenClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load tokenizer and model\n",
    "model_name = 'roberta-large'\n",
    "tokenizer = RobertaTokenizerFast.from_pretrained(model_name, add_prefix_space=True)\n",
    "model = RobertaForTokenClassification.from_pretrained(model_name, num_labels=len(label_list), label2id=label2id, id2label=id2label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "01d322cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing datasets...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 4015/4015 [00:01<00:00, 3326.15 examples/s]\n",
      "Map: 100%|██████████| 223/223 [00:00<00:00, 2764.46 examples/s]\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results/Timex3-NER\",\n",
    "    logging_dir=\"./logs\",\n",
    "    eval_strategy=\"steps\",\n",
    "    save_strategy=\"steps\",\n",
    "    logging_steps=100,\n",
    "    num_train_epochs=1,\n",
    "    save_total_limit=1,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=32,\n",
    "    learning_rate=5e-5,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\"\n",
    ")\n",
    "\n",
    "model_instance = Model(\n",
    "    device=device,\n",
    "    model_name=model_name,\n",
    "    tokenizer=tokenizer,\n",
    "    model=model,\n",
    "    label_list=label_list\n",
    ")\n",
    "\n",
    "model_instance.set_training_args(training_args)\n",
    "tokenized_datasets = model_instance.tokenize_datasets(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e9611289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='139' max='251' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [139/251 37:24 < 30:35, 0.06 it/s, Epoch 0.55/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.046000</td>\n",
       "      <td>0.052321</td>\n",
       "      <td>0.757353</td>\n",
       "      <td>0.746377</td>\n",
       "      <td>0.751825</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mmodel_instance\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokenized_datasets\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\GeoTKG\\Model.py:94\u001b[39m, in \u001b[36mModel.train\u001b[39m\u001b[34m(self, tokenized_datasets)\u001b[39m\n\u001b[32m     84\u001b[39m trainer = Trainer(\n\u001b[32m     85\u001b[39m     model=\u001b[38;5;28mself\u001b[39m.model,\n\u001b[32m     86\u001b[39m     args=\u001b[38;5;28mself\u001b[39m.training_args,\n\u001b[32m   (...)\u001b[39m\u001b[32m     91\u001b[39m     tokenizer=\u001b[38;5;28mself\u001b[39m.tokenizer\n\u001b[32m     92\u001b[39m )\n\u001b[32m     93\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mStarting training...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m94\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     95\u001b[39m \u001b[38;5;28mself\u001b[39m.trainer = trainer\n\u001b[32m     96\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m trainer\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\GeoTKG\\GeoTKG\\Lib\\site-packages\\transformers\\trainer.py:2206\u001b[39m, in \u001b[36mTrainer.train\u001b[39m\u001b[34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[39m\n\u001b[32m   2204\u001b[39m         hf_hub_utils.enable_progress_bars()\n\u001b[32m   2205\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2206\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2207\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2208\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2209\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2210\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2211\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\GeoTKG\\GeoTKG\\Lib\\site-packages\\transformers\\trainer.py:2553\u001b[39m, in \u001b[36mTrainer._inner_training_loop\u001b[39m\u001b[34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[39m\n\u001b[32m   2547\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[32m   2548\u001b[39m     tr_loss_step = \u001b[38;5;28mself\u001b[39m.training_step(model, inputs, num_items_in_batch)\n\u001b[32m   2550\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   2551\u001b[39m     args.logging_nan_inf_filter\n\u001b[32m   2552\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[32m-> \u001b[39m\u001b[32m2553\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m (torch.isnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43misinf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_loss_step\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m   2554\u001b[39m ):\n\u001b[32m   2555\u001b[39m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[32m   2556\u001b[39m     tr_loss = tr_loss + tr_loss / (\u001b[32m1\u001b[39m + \u001b[38;5;28mself\u001b[39m.state.global_step - \u001b[38;5;28mself\u001b[39m._globalstep_last_logged)\n\u001b[32m   2557\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "model_instance.train(tokenized_datasets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a098601a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GeoTKG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
